{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93376bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfca256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from transformers import BertModel\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34c4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Po mnoha letech provokací z ruské strany zahájilo Rusko 24. února 2022 rozsáhlou invazi na Ukrajinu ve snaze ovládnout zemi během několika dní. Ukrajina se dokázala úspěšně bránit a zatlačit ruskou armádu a osvobozuje stále větší část svého území. Mnoho evropských zemí a USA odsoudili ruský útok a pomáhají Ukrajině s dovozem zbraní, humanitární pomocí a také s přijímáním mnoha uprchlíků z Ukrajiny. Na Rusko bylo uvaleno mnoho ekonomických sankcí. Rusko rovněž vede hybridní válku šířením lží po celém internetu prostřednictvím sociálních sítí, zejména v regionu střední Evropy. Mnoho politiků volá po mírových rozhovorech, které by znamenaly odevzdání některých ukrajinských území Rusku, což je pro Ukrajince nepřijatelné. Na druhou stranu ruská agrese přesvědčila neutrální země jako Finsko a Švédsko, aby vstoupily do NATO. Ukrajinský prezident Zelenskyj je od začátku invaze symbolem svobody. Na druhé straně byl ruský prezident Putin symbolem autokracie, propagandy a extremistů. Válka stále pokračuje, ruské síly vytvořily řadu zákopových linií na obranu zabraných území, což znamenalo zastavení ukrajinské ofenzívy. I když prezident Zelenskyj projevuje svou vděčnost západním zemím, stále říká, že Ukrajina dostává jen tolik zbraní, aby se bránila, ale ne tolik, aby porazila Rusko. Západní svět se bojí jaderných zbraní provozovaných Ruskem. Premiér Petr Fiala schvaluje pomoc, která je posílána Ukrajině. Byl jedním z prvních evropských politiků, kteří navštívili prezidenta Zelenského v Kyjevě na Ukrajině. Současná česká vláda je jednou z nejvíce proukrajinských a protiruských vlád na světě.\"\n",
    "text2 = \"Konflikt mezi Izraelem a Hamásem začal 7. října 2023, kdy byla z pásma Gazy vypálena palba tisíců raket namířených na Izrael a asi 3000 ozbrojených teroristů prolomilo zeď oddělující Izrael a Gazu a zaútočilo na nedaleké vesnice, rabovali, znásilňovali a zabíjeli. Zpátky s sebou vzali přibližně 240 rukojmí zpět do Gazy. Izrael odpověděl a odřízl Gazu od vody a zásob a začal na Gazu odpalovat rakety. O několik týdnů později Izrael zahájil invazi do pásma Gazy. Hamas se snaží vyměnit rukojmí za Palestince držené v izraelských věznicích. Koncem listopadu se na několik dní konalo příměří. V Evropě a Asii se konalo mnoho protestů za palestinský lid, aby Izrael zastavil válku a pustil do Gazy humanitární pomoc. Dosud Izrael vpustil určitou pomoc od mnoha mezinárodních humanitárních organizací. Do dnes zemřelo v palestině přes deset tisíc lidí, převážně dětí. Společenská podpora izraele v České republice je velmi velká. Petr Fiala vyjádřil podporu izraelské vládě a zdůraznil právo izraelského lidu na sebeobranu.\"\n",
    "text3 = \"Prezidentské volby se v České republice konaly v lednu 2023. První kolo vyhrál Petr Pavel, bývalý předseda Vojenského výboru NATO, Petr Pavel byl proNATO, proevropský a prozápadní kandidát.Současný český premiér projevil podporu Petru Pavlovi. Těsně na druhém místě skončil populistický kandidát, bývalý premiér Andrej Babiš, který vyjádřil nesouhlas s českou účastí ve válce na Ukrajině a s neschopností vlády starat se o lidi. Druhé kolo se konalo 27. a 28. ledna. Andrej Babiš byl odpůrce Petra Fialy. Petr Pavel vyhrál druhé kolo proti Babišovi se ziskem 58,33 % hlasů a stal se nově zvoleným prezidentem České republiky. Do funkce se ujal 9. března 2023 a nahradil Zemana. Babiš uznal Pavlovu Volební účast ve druhém kole byla mírně nad 70 %, což je nejvyšší v přímé české prezidentské volbě a nejvyšší ve všech národních českých volbách od roku 1998. Petr Fiala má s prezidentem Petrem Pavlem sdílí prozápadní hodnoty. \"\n",
    "text4 = \"Slovenské parlamentní volby se konaly v září 2023 poté, co předchozí vláda Igora Matoviče prohrála hlasování o nedůvěře. Vítěz voleb, levicový populista a proruský politik Robert Fico  dokázal sestavit vládu se sociálně demokratickou stranou HLAS a Slovenskou národní stranou. Robert Fico vedl kampaň šířením dezinformací, lží a kritikou evropské vlády, Ukrajiny a myšlenek liberální demokracie. Během posledních pár let měli vyšetřovatelé plné ruce práce s odhalováním mnoha korupčních obchodů, které byly uskutečněny za Ficovy předchozí vlády. Petr Fiala s Ficem nesdílí názory na proruskou orientaci země. Po volební noci ale Ficovi pogratuloval a popřál Slovensku „dobrou vládu“ v naději, že Česká a Slovenská republika udrží své skvělé vztahy, což není zcela jisté.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b74cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ukraine = [\n",
    "    \"Kdy začala konflikt na Ukrajině a jaký byl jeho původ?\",\n",
    "    \"Jaký byl vliv anexe Krymu na eskalaci konfliktu?\",\n",
    "    \"Které země podporují Ukrajinu a které podporují separatisty?\",\n",
    "    \"Jaká je aktuální humanitární situace v postižených oblastech?\",\n",
    "    \"Jaké jsou diplomatické snahy o řešení konfliktu a mírový proces?\",\n",
    "    \"Jaký je vliv války na civilní obyvatelstvo v dané oblasti?\",\n",
    "    \"Které mezinárodní organizace se aktivně angažují ve snaze ukončit konflikt?\",\n",
    "    \"Jaké jsou následky války na ekonomiku Ukrajiny a okolních zemí?\",\n",
    "    \"Existuje nějaký plán obnovy a rekonstrukce po skončení konfliktu?\",\n",
    "    \"Jaký je postoj veřejnosti v různých částech světa k ukrajinskému konfliktu?\"\n",
    "]\n",
    "\n",
    "# Válka v Palestině\n",
    "q_palestine = [\n",
    "    \"Jak vznikl současný konflikt mezi Izraelem a Palestinou?\",\n",
    "    \"Které faktory přispěly k nedávným násilnostem a eskalaci napětí?\",\n",
    "    \"Jaké jsou hlavní body sporu mezi Izraelem a Palestinci?\",\n",
    "    \"Jaké jsou důsledky konfliktu na civilní obyvatelstvo na obou stranách?\",\n",
    "    \"Jaká je role mezinárodní komunity při řešení izraelsko-palestinského konfliktu?\",\n",
    "    \"Existuje nějaký mírový plán nebo jednání mezi stranami konfliktu?\",\n",
    "    \"Jaký je postoj arabských států k izraelsko-palestinskému konfliktu?\",\n",
    "    \"Které mezinárodní organizace monitorují situaci a poskytují humanitární pomoc?\",\n",
    "    \"Jak se promítá konflikt do regionální stability na Blízkém východě?\",\n",
    "    \"Jaký má konflikt vliv na vnímání Izraele a Palestiny ve světě?\"\n",
    "]\n",
    "\n",
    "# České prezidentské volby\n",
    "q_president = [\n",
    "    \"Kdo jsou hlavní kandidáti v nadcházejících českých prezidentských volbách?\",\n",
    "    \"Jaké jsou hlavní politické témata diskutovaná během volební kampaně?\",\n",
    "    \"Jaké jsou klíčové výzvy, kterým bude český prezident čelit v nadcházejícím období?\",\n",
    "    \"Jaký je postoj veřejnosti k jednotlivým kandidátům a jejich programům?\",\n",
    "    \"Jaký je vliv mediálního pokrytí na průběh volební kampaně?\",\n",
    "    \"Jakým způsobem probíhá volební proces a jaký je očekávaný volební účast?\",\n",
    "    \"Které politické strany nebo hnutí podporují jednotliví kandidáti?\",\n",
    "    \"Jaká je role prezidenta v českém politickém systému a jaký má pravomoci?\",\n",
    "    \"Jaké jsou předpokládané důsledky výsledků prezidentských voleb pro politickou scénu v České republice?\",\n",
    "    \"Jaký je vliv prezidentských voleb na vnímání České republiky v mezinárodním kontextu?\"\n",
    "]\n",
    "\n",
    "# Slovenské parlamentní volby\n",
    "q_slovakia = [\n",
    "    \"Kdo jsou hlavní politické strany a kandidáti ve slovenských parlamentních volbách?\",\n",
    "    \"Jaké jsou klíčové politické otázky, které dominují volební kampani?\",\n",
    "    \"Jaký je vztah mezi Slovenskem a Evropskou unií v kontextu voleb?\",\n",
    "    \"Jaký je postoj veřejnosti k jednotlivým politickým stranám a lídrům?\",\n",
    "    \"Jaký je politický systém na Slovensku a jak funguje parlamentní volba?\",\n",
    "    \"Které otázky týkající se ekonomiky a sociální politiky jsou ve volbách klíčové?\",\n",
    "    \"Jaká je role Slovenska v regionálním a mezinárodním kontextu, a jak ovlivňují volby tuto pozici?\",\n",
    "    \"Jaká je očekávaná volební účast a jaké jsou faktory, které ji mohou ovlivnit?\",\n",
    "    \"Jaký je postoj kandidátů k otázkám životního prostředí a udržitelnosti?\",\n",
    "    \"Jak by výsledek voleb mohl ovlivnit vnitřní politické a hospodářské události ve Slovenské republice?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ff38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = \"/home/martin/Coding/DAS-political-confesions/embedding/stopwords-cs.json\"\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    stopwords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b613e709",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     filtered_words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords]\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(filtered_words)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtranslate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text, target_language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     30\u001b[0m     translator\u001b[38;5;241m=\u001b[39m Translator(to_lang\u001b[38;5;241m=\u001b[39mtarget_language)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'translate'"
     ]
    }
   ],
   "source": [
    "json_file_path = \"/home/martin/Coding/DAS-political-confesions/embedding/stopwords-cs.json\"\n",
    "# Open and load the JSON file\n",
    "with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    stopwords = json.load(file)\n",
    "special_characters_mapping = {'š': 's', 'č': 'c', 'ě': 'e', 'ž': 'z', 'ř': 'r', 'ý': 'y', 'á': 'a', 'í': 'i', 'é': 'e', 'ň': 'n'}\n",
    "special_characters_mapping.update({char.upper(): replacement.upper() for char, replacement in special_characters_mapping.items()})\n",
    "\n",
    "def preprocess_text(text, stopwords):\n",
    "    \n",
    "    for special_char, replacement in special_characters_mapping.items():\n",
    "        text = text.replace(special_char, replacement)\n",
    "    \n",
    "    words = text.split()\n",
    "\n",
    "    for i,word in enumerate(words):\n",
    "        if len(word) > 6:\n",
    "            words[i] = word[0:4]\n",
    "#         elif word[-1] in ['a', 'e', 'y', 'o', 'u', 'i']:\n",
    "#             words[i] = word[:-1]\n",
    "#         elif word[-2:] in ['em', 'ám', 'ím', 'ům', 'mi'] and len(word) > 5:\n",
    "#             words[i] = word[:-2]\n",
    "#         elif word[-3:] in ['ech', 'ách', 'ami', 'emi', 'ími', 'ovi', 'ové'] and len(word) > 6:\n",
    "#             words[i] = word[:-3]\n",
    "        \n",
    "    \n",
    "#     words = [word[0:4] for word in words if len(word) > 7]\n",
    "    \n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "from translate import Translator\n",
    "\n",
    "def translate_text(text, target_language='en'):\n",
    "    translator= Translator(to_lang=target_language)\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "# Example usage:\n",
    "text_to_translate = \"Kdo jsou hlavní politické strany a kandidáti ve slovenských parlamentních volbách?\"\n",
    "translated_text = translate_text(text_to_translate, target_language='es')\n",
    "print(f\"Original text: {text_to_translate}\")\n",
    "print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8f7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceddfb8864d486ebc448b52fdbd03fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d926558676bc4bd191ff9081ef875e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "article_hi = \"Ahoj, co si myslíš o konfliktu na ukrajině?\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate Hindi to French\n",
    "tokenizer.src_lang = \"cs_CZ\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_hi,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n",
    ")\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "# => \"Le chef de l 'ONU affirme qu 'il n 'y a pas de solution militaire dans la Syrie.\"\n",
    "\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5970279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_encode(text, tokenizer, chunksize=512):\n",
    "    # Tokenize and encode the input text in chunks\n",
    "    tokens = tokenizer(text, return_tensors='pt', max_length=chunksize, truncation=True, padding=True)\n",
    "\n",
    "    # If the text is longer than the model's maximum sequence length, handle chunking\n",
    "    if tokens['input_ids'].shape[1] > chunksize:\n",
    "        # Assuming tokens is a dictionary containing 'input_ids' and 'attention_mask'\n",
    "        input_id_chunks = torch.split(tokens['input_ids'][0], chunksize - 2)\n",
    "        mask_chunks = torch.split(tokens['attention_mask'][0], chunksize - 2)\n",
    "\n",
    "        # Initialize lists to store modified chunks\n",
    "        modified_input_id_chunks = []\n",
    "        modified_mask_chunks = []\n",
    "\n",
    "        for i in range(len(input_id_chunks)):\n",
    "            # Add special tokens to the beginning and end of each chunk\n",
    "            modified_input_id_chunk = torch.cat([torch.tensor([tokenizer.cls_token_id]), input_id_chunks[i], torch.tensor([tokenizer.sep_token_id])])\n",
    "            modified_mask_chunk = torch.cat([torch.tensor([1]), mask_chunks[i], torch.tensor([1])])\n",
    "\n",
    "            # Pad each chunk individually\n",
    "            pad_len = chunksize - modified_input_id_chunk.shape[0]\n",
    "            if pad_len > 0:\n",
    "                modified_input_id_chunk = torch.cat([modified_input_id_chunk, torch.zeros(pad_len)])\n",
    "                modified_mask_chunk = torch.cat([modified_mask_chunk, torch.zeros(pad_len)])\n",
    "\n",
    "            # Append the modified chunks to the lists\n",
    "            modified_input_id_chunks.append(modified_input_id_chunk)\n",
    "            modified_mask_chunks.append(modified_mask_chunk)\n",
    "\n",
    "        # Stack the modified chunks\n",
    "        tokens['input_ids'] = torch.stack(modified_input_id_chunks)\n",
    "        tokens['attention_mask'] = torch.stack(modified_mask_chunks)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_embeddings(tokens,model):\n",
    "    # Extract input_ids and attention_mask from the tokens dictionary\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "\n",
    "    # Forward pass to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    print(outputs)\n",
    "    # Access the hidden states from the outputs\n",
    "#     hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # Skip the first three elements of the second dimension\n",
    "#     modified_hidden_states = hidden_states[:, 2:, :]\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def create_embedding(hidden_states, aggregation_method='mean'):\n",
    "    # Choose the aggregation method (mean or sum)\n",
    "    if aggregation_method == 'mean':\n",
    "        embedding = hidden_states.mean(dim=1)\n",
    "    elif aggregation_method == 'sum':\n",
    "        embedding = hidden_states.sum(dim=1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid aggregation method. Use 'mean' or 'sum'.\")\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def calculate_similarity(embedding1, embedding2):\n",
    "    # Calculate cosine similarity between two embeddings\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(embedding1, embedding2,)\n",
    "    return cosine_sim\n",
    "\n",
    "# Example usage:\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model_name = \"ufal/robeczech-base\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0898143",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PreTrainedModel.get_input_embeddings() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     text \u001b[38;5;241m=\u001b[39m preprocess_text(text, stopwords)\n\u001b[1;32m      4\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenize_and_encode(text, tokenizer)\n\u001b[0;32m----> 5\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_input_embeddings(tokens)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     hidden_states = get_embeddings(tokens/, model)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     embedding = create_embedding(hidden_states)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(hidden_states)\n",
      "\u001b[0;31mTypeError\u001b[0m: PreTrainedModel.get_input_embeddings() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = []\n",
    "for text in [text1, text2, text3, text4]:\n",
    "    text = preprocess_text(text, stopwords)\n",
    "    tokens = tokenize_and_encode(text, tokenizer)\n",
    "    embedding = model.get_input_embeddings(tokens)\n",
    "#     hidden_states = get_embeddings(tokens/, model)\n",
    "#     embedding = create_embedding(hidden_states)\n",
    "    embeddings.append(hidden_states)\n",
    "\n",
    "question_embeddings = []\n",
    "for question in q_ukraine:\n",
    "    question = preprocess_text(question, stopwords)\n",
    "    tokens = tokenize_and_encode(question, tokenizer)\n",
    "    hidden_states = get_embeddings(tokens, model)\n",
    "    embedding = create_embedding(hidden_states)\n",
    "    question_embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "336f8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_classes = {}\n",
    "\n",
    "for q in question_embeddings:\n",
    "    max_sim = -1\n",
    "    for i,t in enumerate(embeddings):\n",
    "        sim = calculate_similarity(q, t)\n",
    "        if sim > max_sim:\n",
    "#             print(sim)\n",
    "            question_classes[q] = i\n",
    "            max_sim = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d51eaeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for key, value in question_classes.items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "09361f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity1 = calculate_similarity(embedding3, embedding1)\n",
    "\n",
    "# Calculate cosine similarity between question and text2\n",
    "similarity2 = calculate_similarity(embedding3, embedding2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9532b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7223554849624634\n"
     ]
    }
   ],
   "source": [
    "print(similarity1.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1aacd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6489545106887817\n"
     ]
    }
   ],
   "source": [
    "print(similarity2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf1c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "0\n",
    "3\n",
    "1\n",
    "0\n",
    "0\n",
    "3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
