{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25b1c33-5827-4168-98e7-4ead3bd3cc90",
   "metadata": {},
   "source": [
    "# Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405ed24-2aa1-4872-8ff4-0d494d8a3e9f",
   "metadata": {},
   "source": [
    "## Steps to follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdaa35-278a-4ea4-925c-5e858a81bc71",
   "metadata": {},
   "source": [
    "### Understanding Pre-trained Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e16d6c-ba0e-4b64-81cf-54e5a31603c4",
   "metadata": {},
   "source": [
    "<b>Advantages:</b> Pre-trained models like GPT, BERT, and their variants have been trained on massive amounts of data. They already understand the structure of the language and have vast general knowledge. Starting with a pre-trained model and then fine-tuning on your dataset can save time and resources compared to training a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61234b-bb98-4655-857e-4becd2ef1066",
   "metadata": {},
   "source": [
    "<b>\n",
    "Selecting the Right Base Model</b>: OpenAI's GPT series (GPT-2, GPT-3, GPT-4, etc.) is a great starting point for conversational AI tasks. Other models, like BERT or T5, are more suited for specific tasks such as classification or translation. For your specific project, a GPT variant would likely be the most suite.abl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21cbb5c-037b-4d72-a53d-028dd97f1be0",
   "metadata": {},
   "source": [
    "### Model Size:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35e769-18d3-47a4-9277-f12ef97bd46d",
   "metadata": {},
   "source": [
    "<b>Parameter count:</b> Models like GPT-4 can have billions or even hundreds of billions of parameters. A larger model can capture more nuances but requires more computational resources for fine-tuning and can be overkill for smaller data\n",
    "sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b69b8-de47-478c-851e-c38c2067c57b",
   "metadata": {},
   "source": [
    "<b>Dataset Size Consideration:</b> If your dataset is relatively small (a few megabytes or even gigabytes of interview transcripts), using a smaller version of GPT (like GPT-2 or a smaller variant of GPT-3) might be more approp\n",
    "riate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df23cf-5146-4e02-ac17-0a3ad0dbd9bd",
   "metadata": {},
   "source": [
    "### Custom Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64edf56a-a3f2-42f4-b52b-f4d7b29f9c9e",
   "metadata": {},
   "source": [
    "<b>Modifying Existing Models:</b> While the vanilla GPT architecture could work well for your needs, there's always room to experiment. For instance, you might consider tweaking the model's attention mechanism, adding new layers, or integrating other components (e.g., an emotion recognition module)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2417b-4949-457b-b199-44d9c67e951c",
   "metadata": {},
   "source": [
    "<b>Attention Mechanisms:</b> Transformers, which are the backbone of models like GPT, rely on attention mechanisms. There have been advancements and variations in how attention is computed (e.g., axial attention, sparse attention). Depending on your dataset and goals, exploring these can be b\n",
    "eneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249979e8-0af1-4b45-a38a-0ba32b1de318",
   "metadata": {},
   "source": [
    "### Transfer Learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8d37c-7efd-4d15-9f7b-7a803ebdf0ba",
   "metadata": {},
   "source": [
    "<b>Fine-tuning:</b> This involves taking a pre-trained model and continuing its training on your dataset. The goal is to adapt the generic language capabilities of the pre-trained model to the specific style and knowledge of the person in the interviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd99a2d-1852-4f89-a5f3-a41bba388494",
   "metadata": {},
   "source": [
    "<b>Layer Freezing:</b> During fine-tuning, you might decide to freeze (not update) some layers of the model while only updating others. This can be useful to retain more general language knowledge in certain parts of the model while adapting other parts to the specific individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b74533-226f-4c30-b293-690dcfe526fe",
   "metadata": {},
   "source": [
    "### Consideration of Deployment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac728203-8cbc-4ffa-82a3-26512aa3dd15",
   "metadata": {},
   "source": [
    "<b>Model Pruning:</b> Depending on where and how you intend to deploy the model, you might need a more compact version. Model pruning techniques can reduce the size of the model by removing less important parameters while retaining most of its capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adaefb0-71bc-4279-8606-4410460785cc",
   "metadata": {},
   "source": [
    "<b>Quantization:</b> This involves converting model weights from floating-point representation to a lower bit-width representation. It can reduce the model size and make inferences faster, albeit at a slight cost to accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece01cf-78dc-46a8-9d03-78564ac28571",
   "metadata": {},
   "source": [
    "### Environment & Resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd978572-b81e-4970-ab57-5cf4d40a34e3",
   "metadata": {},
   "source": [
    "<b>Hardware:</b> Consider the hardware you have access to. Training large models requires GPUs or TPUs. The size and complexity of the model you select should align with your hardware capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a7603-5f43-44fe-8bc5-9cbb6ed53da7",
   "metadata": {},
   "source": [
    "<b>Software:</b> Ensure that the machine learning framework you're using (e.g., TensorFlow, PyTorch) supports the model architecture you've chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54793f-b8af-4333-b1ad-11704d20bd25",
   "metadata": {},
   "source": [
    "### Model Interpretability:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24b421-622b-477a-90b9-107e39d5e93b",
   "metadata": {},
   "source": [
    "<b>Understanding Outputs:</b> Depending on the use case, you might want to understand why the model is generating certain responses. There are tools and techniques available for transformer model interpretability which can give insights into the model's behavior.hich can give insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7198452-c8e5-4fdc-8ecc-53b6d7534fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>poradi</th>\n",
       "      <th>obdobi</th>\n",
       "      <th>datum</th>\n",
       "      <th>schuze</th>\n",
       "      <th>url</th>\n",
       "      <th>cisloHlasovani</th>\n",
       "      <th>celeJmeno</th>\n",
       "      <th>narozeni</th>\n",
       "      <th>HsProcessType</th>\n",
       "      <th>OsobaId</th>\n",
       "      <th>funkce</th>\n",
       "      <th>tema</th>\n",
       "      <th>text</th>\n",
       "      <th>pocetSlov</th>\n",
       "      <th>politiciZminky</th>\n",
       "      <th>temata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010_19_00925</td>\n",
       "      <td>925</td>\n",
       "      <td>2010</td>\n",
       "      <td>2011-06-14</td>\n",
       "      <td>19</td>\n",
       "      <td>http://www.psp.cz/eknih/2010ps/stenprot/019sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miroslava Němcová</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>miroslava-nemcova-18</td>\n",
       "      <td>Předsedkyně PSP</td>\n",
       "      <td>125. Návrh na zkrácení zákonné lhůty pro proje...</td>\n",
       "      <td>Děkuji paní poslankyni Putnové. Prosím dalšího...</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017_50_00385</td>\n",
       "      <td>385</td>\n",
       "      <td>2017</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>50</td>\n",
       "      <td>http://www.psp.cz/eknih/2017ps/stenprot/050sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radek Vondráček</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>radek-vondracek</td>\n",
       "      <td>Předseda PSP</td>\n",
       "      <td>3. Informace vlády o&amp;nbsp;nákupech zdravotnick...</td>\n",
       "      <td>Děkuji. Mám zde dvě přihlášky s přednostním pr...</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017_1_00243</td>\n",
       "      <td>243</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.psp.cz/eknih/2017ps/stenprot/001sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan Hamáček</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>jan-hamacek</td>\n",
       "      <td>Předsedající</td>\n",
       "      <td>9. Návrh na volbu předsedy Poslanecké sněmovny...</td>\n",
       "      <td>Děkuji. Pan poslanec Bartoš stáhl? (Poslanec B...</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002_35_00020</td>\n",
       "      <td>20</td>\n",
       "      <td>2002</td>\n",
       "      <td>2004-09-21</td>\n",
       "      <td>35</td>\n",
       "      <td>http://www.psp.cz/eknih/2002ps/stenprot/035sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lubomír Zaorálek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>lubomir-zaoralek</td>\n",
       "      <td>Předseda PSP</td>\n",
       "      <td>Zahájení schůze</td>\n",
       "      <td>Dneska tedy bychom tím začali? (Ano.)\\nPo panu...</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017_102_00014</td>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>102</td>\n",
       "      <td>http://www.psp.cz/eknih/2017ps/stenprot/102sch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radek Vondráček</td>\n",
       "      <td>NaN</td>\n",
       "      <td>person</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Předseda PSP</td>\n",
       "      <td>Zahájení schůze</td>\n",
       "      <td>Já vám děkuji. Nyní pan předseda Bartoš, připr...</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id  poradi  obdobi       datum  schuze  \\\n",
       "0   2010_19_00925     925    2010  2011-06-14      19   \n",
       "1   2017_50_00385     385    2017  2020-06-04      50   \n",
       "2    2017_1_00243     243    2017  2017-11-22       1   \n",
       "3   2002_35_00020      20    2002  2004-09-21      35   \n",
       "4  2017_102_00014      14    2017  2021-05-12     102   \n",
       "\n",
       "                                                 url  cisloHlasovani  \\\n",
       "0  http://www.psp.cz/eknih/2010ps/stenprot/019sch...             NaN   \n",
       "1  http://www.psp.cz/eknih/2017ps/stenprot/050sch...             NaN   \n",
       "2  http://www.psp.cz/eknih/2017ps/stenprot/001sch...             NaN   \n",
       "3  http://www.psp.cz/eknih/2002ps/stenprot/035sch...             NaN   \n",
       "4  http://www.psp.cz/eknih/2017ps/stenprot/102sch...             NaN   \n",
       "\n",
       "           celeJmeno  narozeni HsProcessType               OsobaId  \\\n",
       "0  Miroslava Němcová       NaN        person  miroslava-nemcova-18   \n",
       "1    Radek Vondráček       NaN        person       radek-vondracek   \n",
       "2        Jan Hamáček       NaN        person           jan-hamacek   \n",
       "3   Lubomír Zaorálek       NaN        person      lubomir-zaoralek   \n",
       "4    Radek Vondráček       NaN        person                   NaN   \n",
       "\n",
       "            funkce                                               tema  \\\n",
       "0  Předsedkyně PSP  125. Návrh na zkrácení zákonné lhůty pro proje...   \n",
       "1     Předseda PSP  3. Informace vlády o&nbsp;nákupech zdravotnick...   \n",
       "2     Předsedající  9. Návrh na volbu předsedy Poslanecké sněmovny...   \n",
       "3     Předseda PSP                                    Zahájení schůze   \n",
       "4     Předseda PSP                                    Zahájení schůze   \n",
       "\n",
       "                                                text  pocetSlov  \\\n",
       "0  Děkuji paní poslankyni Putnové. Prosím dalšího...         24   \n",
       "1  Děkuji. Mám zde dvě přihlášky s přednostním pr...         25   \n",
       "2  Děkuji. Pan poslanec Bartoš stáhl? (Poslanec B...         26   \n",
       "3  Dneska tedy bychom tím začali? (Ano.)\\nPo panu...         27   \n",
       "4  Já vám děkuji. Nyní pan předseda Bartoš, připr...         27   \n",
       "\n",
       "   politiciZminky  temata  \n",
       "0             NaN     NaN  \n",
       "1             NaN     NaN  \n",
       "2             NaN     NaN  \n",
       "3             NaN     NaN  \n",
       "4             NaN     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"./data/data_example.csv\"\n",
    "data_raw = pd.read_csv(path)\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4cd55f-38df-4a08-9431-37b10a949619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiri.nabelek\\FJFI\\DAS-Political_confessions\\env_llm\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 1. Select and Load the Model & Tokenizer\n",
    "model_name = \"gpt2-medium\"  # You can select \"gpt2-small\", \"gpt2-medium\", \"gpt2-large\", or \"gpt2-xl\" depending on needs\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. Dataset Preparation (Simple Example)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return encoding[\"input_ids\"].squeeze(), encoding[\"attention_mask\"].squeeze()\n",
    "\n",
    "# Example data\n",
    "data = [\"This is an example sentence from an interview.\", \"Another sample text goes here.\"]\n",
    "dataset = CustomDataset(data, tokenizer, max_length=50)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 3. Fine-tuning Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(dataloader) * 3) # Assuming 3 epochs\n",
    "\n",
    "# 4. Fine-tuning Loop\n",
    "model.train()\n",
    "for epoch in range(3):  # 3 epochs as an example\n",
    "    for batch in dataloader:\n",
    "        inputs, masks = batch\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, attention_mask=masks, labels=inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "print(\"Fine-tuning complete!\")\n",
    "\n",
    "# You can now use the model for generating responses or save it for later use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88038b-4757-44f1-bcf1-84b41ede1038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
